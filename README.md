# ProtGO
## A Transformer based fusion model for accurately predicting Gene Ontology (GO) terms from full-scale Protein Sequences

Recent developments in next-generation sequencing technology have led to the creation of extensive, open-source protein databases consisting of hundreds of millions of sequences. To render these sequences applicable
in biomedical applications, they must be meticulously annotated by wet lab testing or extracting them from
existing literature. Over the last few years, researchers have developed numerous automatic annotation
systems, particularly deep learning models based on machine learning and artificial intelligence, to address
this issue. In this work, we propose a transformer-based fusion model capable of predicting Gene Ontology (GO)
terms from full-scale protein sequences, achieving state-of-the-art accuracy compared to other contemporary
machine learning annotation systems. The approach performs particularly well on clustered split datasets,
which comprise training and testing samples originating from distinct distributions that are structurally
diverse. This demonstrates that the model is able to understand both short and long-term dependencies
within the enzymeâ€™s structure and can precisely identify the motifs associated with the various GO terms.
Furthermore, the technique is lightweight and less computationally expensive compared to the benchmark
methods, while at the same time not unaffected by sequence length, rendering it appropriate for diverse
applications with varying sequence lengths.



